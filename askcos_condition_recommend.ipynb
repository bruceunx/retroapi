{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TGH_kv20mS0c"
      },
      "outputs": [],
      "source": [
        "! sh ./download.sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPzKImc6n7rJ",
        "outputId": "c35ed906-a1a5-4837-ee68-bfae81fe87ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2023.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rdkit) (1.23.5)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit) (9.4.0)\n",
            "Installing collected packages: rdkit\n",
            "Successfully installed rdkit-2023.9.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC, abstractmethod\n",
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "class ReactionContextRecommender(ABC):\n",
        "    @abstractmethod\n",
        "    def recommend(\n",
        "        self, smi: str, reagents: Optional[List[str]], n_conditions: int, *args, **kwargs\n",
        "    ) -> list:\n",
        "        \"\"\"Predict reaction conditions for the input reaction SMILES.\n",
        "\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        smi : str\n",
        "            the reaction SMILES including reactants and products\n",
        "        reagents : list[str] | None\n",
        "            additional reagents not included in the reaction SMILES.\n",
        "            NOTE: this may be ignored depending on the implementation\n",
        "        n_conditions : int\n",
        "            the number of conditions to return\n",
        "        *args, **kwargs\n",
        "            additional positional and keyword arguments\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        list\n",
        "            a list of conditions, the format of which is implementation-dependent\n",
        "        \"\"\"\n",
        "\n",
        "    def predict(self, smiles: str, reagents: Optional[List[str]], n_conditions: int, *args, **kwargs):\n",
        "        return self.recommend(smiles, reagents, n_conditions, *args, **kwargs)\n"
      ],
      "metadata": {
        "id": "5UuKwrBooGly"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from dataclasses import dataclass\n",
        "from os import PathLike\n",
        "\n",
        "\n",
        "@dataclass(frozen=True)\n",
        "class ContextConfig:\n",
        "    model_path: PathLike\n",
        "    info_path: str\n",
        "    weights_path: PathLike\n",
        "    ehs_score_path: PathLike\n",
        "\n",
        "\n",
        "RESOURCES_DIR = Path(\"./app/resources\")\n",
        "CONTEXT_DIR = RESOURCES_DIR / \"models\" / \"context\" / \"v1\"\n",
        "\n",
        "DEFAULT_CONFIG = ContextConfig(\n",
        "    CONTEXT_DIR / \"model.json\",\n",
        "    CONTEXT_DIR,\n",
        "    CONTEXT_DIR / \"weights.h5\",\n",
        "    CONTEXT_DIR / \"ehs_solvent_scores.csv\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "GCQZ210RojC0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple\n",
        "from rdkit.Chem import AllChem, DataStructs\n",
        "\n",
        "def mol_smi_to_morgan_fp(\n",
        "    smi: str,\n",
        "    radius: int = 2,\n",
        "    length: int = 2048,\n",
        "    as_column: bool = False,\n",
        "    raise_exceptions: bool = False,\n",
        "    dtype: str = \"float32\",\n",
        "    **fp_kwargs,\n",
        ") -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Create Morgan Fingerprint from molecule SMILES.\n",
        "    Returns correctly shaped zero vector on errors.\n",
        "\n",
        "    Args:\n",
        "        smi (str): input molecule SMILES\n",
        "        radius (int, optional): fingerprint radius, default 2\n",
        "        length (int, optional): fingerprint length, default 2048\n",
        "        as_column (bool, optional): return fingerprint as column vector\n",
        "        raise_exceptions (bool, optional): raise exceptions instead of returning zero vector\n",
        "        dtype (str, optional): data type of the generated fingerprint array\n",
        "        **kwargs: passed to GetMorganFingerprintAsBitVect\n",
        "\n",
        "    Returns:\n",
        "        np.array of shape (length,) or (1, length) if as_column = True\n",
        "    \"\"\"\n",
        "    try:\n",
        "        mol = Chem.MolFromSmiles(smi)\n",
        "    except Exception as e:\n",
        "        logger.warning(f\"Unable to parse SMILES {smi}: {e!s}\")\n",
        "        if raise_exceptions:\n",
        "            raise\n",
        "        fp = np.zeros(length, dtype)\n",
        "    else:\n",
        "        try:\n",
        "            fp_bit = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=length, **fp_kwargs)\n",
        "            fp = np.empty(length, dtype)\n",
        "            DataStructs.ConvertToNumpyArray(fp_bit, fp)\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Unable to generate fingerprint for {smi}: {e!s}\")\n",
        "            if raise_exceptions:\n",
        "                raise\n",
        "            fp = np.zeros(length, dtype)\n",
        "\n",
        "    if as_column:\n",
        "        return fp.reshape(1, -1)\n",
        "    else:\n",
        "        return fp\n",
        "\n",
        "\n",
        "def reac_prod_smi_to_morgan_fp(\n",
        "    reactant: str,\n",
        "    pdt: str,\n",
        "    radius: int = 2,\n",
        "    length: int = 2048,\n",
        "    as_column: bool = False,\n",
        "    raise_exceptions: bool = False,\n",
        "    **fp_kwargs,\n",
        ") -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"\n",
        "    Create Morgan Fingerprints from reactant and product SMILES separately.\n",
        "\n",
        "    Args:\n",
        "        rsmi (str): reactant molecule SMILES\n",
        "        psmi (str): product molecule SMILES\n",
        "        radius (int, optional): fingerprint radius, default 2\n",
        "        length (int, optional): fingerprint length, default 2048\n",
        "        as_column (bool, optional): return fingerprints as column vector\n",
        "        raise_exceptions (bool, optional): raise exceptions instead of returning zero vector\n",
        "        **kwargs: passed to GetMorganFingerprintAsBitVect\n",
        "\n",
        "    Returns:\n",
        "        product np.array of shape (length,) or (1, length) if as_column = True\n",
        "        reactant np.array of shape (length,) or (1, length) if as_column = True\n",
        "    \"\"\"\n",
        "    params = dict(\n",
        "        radius=radius, length=length, as_column=as_column, raise_exceptions=raise_exceptions\n",
        "    )\n",
        "    rfp = mol_smi_to_morgan_fp(reactant, **params, **fp_kwargs)\n",
        "    pfp = mol_smi_to_morgan_fp(pdt, **params, **fp_kwargs)\n",
        "\n",
        "    return pfp, rfp\n",
        "\n"
      ],
      "metadata": {
        "id": "yWt2HbzfpFXu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Edited version (maybe only work for cleaned API)\n",
        "import logging\n",
        "from os import PathLike\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from scipy import stats\n",
        "from typing import List, Optional\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class NeuralNetContextRecommender(ReactionContextRecommender):\n",
        "    \"\"\"Reaction condition predictor using neural network architecture\"\"\"\n",
        "\n",
        "    def __init__(self, with_smiles: bool = False, config: ContextConfig = DEFAULT_CONFIG, **kwargs):\n",
        "        \"\"\"Initializes Neural Network predictor.\n",
        "\n",
        "        Args:\n",
        "            with_smiles (bool, optional): Remove predictions which only have\n",
        "                a name and no SMILES string (default: {False})\n",
        "        \"\"\"\n",
        "        # Full neural network model\n",
        "        self.nnModel = None\n",
        "\n",
        "        # Index to label dictionaries\n",
        "        self.c1_dict = None\n",
        "        self.s1_dict = None\n",
        "        self.s2_dict = None\n",
        "        self.r1_dict = None\n",
        "        self.r2_dict = None\n",
        "\n",
        "        # Input/output dimensions (should equal size of dictionaries)\n",
        "        self.c1_dim = None\n",
        "        self.r1_dim = None\n",
        "        self.r2_dim = None\n",
        "        self.s1_dim = None\n",
        "        self.s2_dim = None\n",
        "\n",
        "        # Functions for evaluating sub-component of full model\n",
        "        self.fp_func = None\n",
        "        self.c1_func = None\n",
        "        self.s1_func = None\n",
        "        self.s2_func = None\n",
        "        self.r1_func = None\n",
        "        self.r2_func = None\n",
        "        self.T_func = None\n",
        "\n",
        "        self.with_smiles = with_smiles\n",
        "        self.fp_size = None  # 2048\n",
        "        self.ehs_dict = {}\n",
        "\n",
        "        self.model_path = config.model_path\n",
        "        self.info_path = config.info_path\n",
        "        self.weights_path = config.weights_path\n",
        "        self.ehs_score_path = config.ehs_score_path\n",
        "\n",
        "    def validate_paths(self):\n",
        "        \"\"\"Check that the configured paths exist.\n",
        "\n",
        "        Raises\n",
        "        ------\n",
        "        ValueError\n",
        "            if any of the paths do not exist\n",
        "        \"\"\"\n",
        "        paths = [self.model_path, self.info_path, self.weights_path, self.ehs_score_path]\n",
        "\n",
        "        for path in paths:\n",
        "            if path is None or not Path(path).exists():\n",
        "                raise ValueError(f\"Missing path for {self.__class__.__name__}: {path}\")\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\"Load the configured model\"\"\"\n",
        "        self.load_nn_model(self.model_path, self.info_path, self.weights_path)\n",
        "        self.load_ehs_dictionary(self.ehs_score_path)\n",
        "\n",
        "        logger.info(\"Neural network context recommender has been loaded.\")\n",
        "\n",
        "        return self\n",
        "\n",
        "    def load_nn_model(self, model_path: PathLike, info_path: PathLike, weights_path: PathLike):\n",
        "        \"\"\"Loads specified Neural Network model.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        model_path : PathLike\n",
        "        info_path : PathLike\n",
        "        weights_path : PathLike\n",
        "        \"\"\"\n",
        "        if not model_path:\n",
        "            logger.error(\n",
        "                \"Cannot load neural net context recommender without a specific path to the model. Exiting...\"\n",
        "            )\n",
        "        if not info_path:\n",
        "            logger.error(\n",
        "                \"Cannot load neural net context recommender without a specific path to the model info. Exiting...\"\n",
        "            )\n",
        "\n",
        "        # load json and create model\n",
        "        with open(model_path, \"r\") as f:\n",
        "            loaded_model_json = f.read()\n",
        "\n",
        "        self.nnModel = tf.keras.models.model_from_json(loaded_model_json)\n",
        "        # load weights into new model\n",
        "        self.nnModel.load_weights(weights_path)\n",
        "        # get fp_size based on the model\n",
        "        self.fp_size = self.nnModel.input_shape[0][1]\n",
        "\n",
        "        # load label dictionaries\n",
        "        info_path = Path(info_path)\n",
        "        r1_dict_file = info_path / \"r1_dict.pickle\"\n",
        "        r2_dict_file = info_path / \"r2_dict.pickle\"\n",
        "        s1_dict_file = info_path / \"s1_dict.pickle\"\n",
        "        s2_dict_file = info_path / \"s2_dict.pickle\"\n",
        "        c1_dict_file = info_path / \"c1_dict.pickle\"\n",
        "\n",
        "        with open(r1_dict_file, \"rb\") as R1_DICT_F:\n",
        "            self.r1_dict = pickle.load(R1_DICT_F)\n",
        "\n",
        "        with open(r2_dict_file, \"rb\") as R2_DICT_F:\n",
        "            self.r2_dict = pickle.load(R2_DICT_F)\n",
        "\n",
        "        with open(s1_dict_file, \"rb\") as S1_DICT_F:\n",
        "            self.s1_dict = pickle.load(S1_DICT_F)\n",
        "\n",
        "        with open(s2_dict_file, \"rb\") as S2_DICT_F:\n",
        "            self.s2_dict = pickle.load(S2_DICT_F)\n",
        "\n",
        "        with open(c1_dict_file, \"rb\") as C1_DICT_F:\n",
        "            self.c1_dict = pickle.load(C1_DICT_F)\n",
        "\n",
        "        # extract input/output dimensions from model\n",
        "        self.c1_dim = self.nnModel.input_shape[2][1]\n",
        "        self.r1_dim = self.nnModel.input_shape[3][1]\n",
        "        self.r2_dim = self.nnModel.input_shape[4][1]\n",
        "        self.s1_dim = self.nnModel.input_shape[5][1]\n",
        "        self.s2_dim = self.nnModel.input_shape[6][1]\n",
        "\n",
        "        (\n",
        "            input_pfp,\n",
        "            input_rxnfp,\n",
        "            input_c1,\n",
        "            input_r1,\n",
        "            input_r2,\n",
        "            input_s1,\n",
        "            input_s2,\n",
        "        ) = self.nnModel.inputs\n",
        "\n",
        "        # add an intermediate input to the model which feeds into dropout_1\n",
        "        # [input_pfp, input_rxnfp] -> fp_transform1 -> fp_transform2 -> dropout_1\n",
        "        # this allows computing the first 2 layers once\n",
        "        # the new input must be fed through the remainder of the model\n",
        "        h2 = self.nnModel.get_layer(\"fp_transform2\").output\n",
        "        input_h2 = tf.keras.Input(shape=(1000,), name=\"input_h2\")\n",
        "\n",
        "        h2_dropout = self.nnModel.get_layer(\"dropout_1\")(input_h2)\n",
        "\n",
        "        c1_h1 = self.nnModel.get_layer(\"c1_h1\")(h2_dropout)\n",
        "        c1_h2 = self.nnModel.get_layer(\"c1_h2\")(c1_h1)\n",
        "        c1_output = self.nnModel.get_layer(\"c1\")(c1_h2)\n",
        "        c1_dense = self.nnModel.get_layer(\"c1_dense\")(input_c1)\n",
        "\n",
        "        concat_fp_c1 = self.nnModel.get_layer(\"concat_fp_c1\")([h2_dropout, c1_dense])\n",
        "\n",
        "        s1_h1 = self.nnModel.get_layer(\"s1_h1\")(concat_fp_c1)\n",
        "        s1_h2 = self.nnModel.get_layer(\"s1_h2\")(s1_h1)\n",
        "\n",
        "        s1_output = self.nnModel.get_layer(\"s1\")(s1_h2)\n",
        "        s1_dense = self.nnModel.get_layer(\"s1_dense\")(input_s1)\n",
        "\n",
        "        concat_fp_c1_s1 = self.nnModel.get_layer(\"concat_fp_c1_s1\")(\n",
        "            [h2_dropout, c1_dense, s1_dense]\n",
        "        )\n",
        "\n",
        "        s2_h1 = self.nnModel.get_layer(\"s2_h1\")(concat_fp_c1_s1)\n",
        "        s2_h2 = self.nnModel.get_layer(\"s2_h2\")(s2_h1)\n",
        "\n",
        "        s2_output = self.nnModel.get_layer(\"s2\")(s2_h2)\n",
        "        s2_dense = self.nnModel.get_layer(\"s2_dense\")(input_s2)\n",
        "\n",
        "        concat_fp_c1_s1_s2 = self.nnModel.get_layer(\"concat_fp_c1_s1_s2\")(\n",
        "            [h2_dropout, c1_dense, s1_dense, s2_dense]\n",
        "        )\n",
        "\n",
        "        r1_h1 = self.nnModel.get_layer(\"r1_h1\")(concat_fp_c1_s1_s2)\n",
        "        r1_h2 = self.nnModel.get_layer(\"r1_h2\")(r1_h1)\n",
        "\n",
        "        r1_output = self.nnModel.get_layer(\"r1\")(r1_h2)\n",
        "        r1_dense = self.nnModel.get_layer(\"r1_dense\")(input_r1)\n",
        "\n",
        "        concat_fp_c1_s1_s2_r1 = self.nnModel.get_layer(\"concat_fp_c1_s1_s2_r1\")(\n",
        "            [h2_dropout, c1_dense, s1_dense, s2_dense, r1_dense]\n",
        "        )\n",
        "\n",
        "        r2_h1 = self.nnModel.get_layer(\"r2_h1\")(concat_fp_c1_s1_s2_r1)\n",
        "        r2_h2 = self.nnModel.get_layer(\"r2_h2\")(r2_h1)\n",
        "\n",
        "        r2_output = self.nnModel.get_layer(\"r2\")(r2_h2)\n",
        "        r2_dense = self.nnModel.get_layer(\"r2_dense\")(input_r2)\n",
        "\n",
        "        concat_fp_c1_s1_s2_r1_r2 = self.nnModel.get_layer(\"concat_fp_c1_s1_s2_r1_r2\")(\n",
        "            [h2_dropout, c1_dense, s1_dense, s2_dense, r1_dense, r2_dense]\n",
        "        )\n",
        "\n",
        "        T_h1 = self.nnModel.get_layer(\"T_h1\")(concat_fp_c1_s1_s2_r1_r2)\n",
        "\n",
        "        T_output = self.nnModel.get_layer(\"T\")(T_h1)\n",
        "\n",
        "        # create functions for each of the sub-model evaluations\n",
        "        self.fp_func = tf.function(tf.keras.Model([input_pfp, input_rxnfp], [h2]))\n",
        "        self.c1_func = tf.function(tf.keras.Model([input_h2], [c1_output]))\n",
        "        self.s1_func = tf.function(tf.keras.Model([input_h2, input_c1], [s1_output]))\n",
        "        self.s2_func = tf.function(tf.keras.Model([input_h2, input_c1, input_s1], [s2_output]))\n",
        "        self.r1_func = tf.function(\n",
        "            tf.keras.Model([input_h2, input_c1, input_s1, input_s2], [r1_output])\n",
        "        )\n",
        "        self.r2_func = tf.function(\n",
        "            tf.keras.Model([input_h2, input_c1, input_s1, input_s2, input_r1], [r2_output])\n",
        "        )\n",
        "        self.T_func = tf.function(\n",
        "            tf.keras.Model([input_h2, input_c1, input_s1, input_s2, input_r1, input_r2], [T_output])\n",
        "        )\n",
        "\n",
        "    def smiles_to_fp(self, smiles):\n",
        "        \"\"\"Generates fingerprints for the input reaction SMILES.\n",
        "\n",
        "        Canonicalizes and removes atom map numbers before generation.\n",
        "\n",
        "        Args:\n",
        "            smiles (str): input reaction SMILES\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray, np.ndarray: product and reaction fingerprints with dtype of int8\n",
        "        \"\"\"\n",
        "        rsmi, _, psmi = smiles.split(\">\")\n",
        "        rct_mol = Chem.MolFromSmiles(rsmi)\n",
        "        prd_mol = Chem.MolFromSmiles(psmi)\n",
        "        [\n",
        "            atom.ClearProp(\"molAtomMapNumber\")\n",
        "            for atom in rct_mol.GetAtoms()\n",
        "            if atom.HasProp(\"molAtomMapNumber\")\n",
        "        ]\n",
        "        [\n",
        "            atom.ClearProp(\"molAtomMapNumber\")\n",
        "            for atom in prd_mol.GetAtoms()\n",
        "            if atom.HasProp(\"molAtomMapNumber\")\n",
        "        ]\n",
        "        rsmi = Chem.MolToSmiles(rct_mol, isomericSmiles=True)\n",
        "        psmi = Chem.MolToSmiles(prd_mol, isomericSmiles=True)\n",
        "        pfp, rfp = reac_prod_smi_to_morgan_fp(\n",
        "            rsmi, psmi, length=self.fp_size, as_column=True, useFeatures=False, useChirality=True\n",
        "        )\n",
        "        rxnfp = pfp - rfp\n",
        "        return pfp, rxnfp\n",
        "\n",
        "    def recommend(\n",
        "            self,\n",
        "            smi: str,\n",
        "            reagents: Optional[List[str]],\n",
        "            n_conditions: int,\n",
        "            with_smiles=False,\n",
        "            return_scores=True,\n",
        "            return_separate=False,\n",
        "            **kwargs,\n",
        "    ) -> list:\n",
        "        \"\"\"\n",
        "        Parameters\n",
        "        ----------\n",
        "        smi : str\n",
        "            SMILES string for reaction., by default None\n",
        "        reagents : list[str] | None, default=None\n",
        "            NOTE: unused, maintained only for signature compatibility\n",
        "        n_conditions : int, default=10\n",
        "        with_smiles : bool, default=False\n",
        "            remove predictions that have only a name and no SMILES string\n",
        "        return_scores : bool, default=True\n",
        "            return the scores of the recommendations as well\n",
        "        return_separate : bool, default=False\n",
        "            return predictions directly without postprocessing\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        _type_\n",
        "            _description_\n",
        "        \"\"\"\n",
        "        return self.get_n_conditions(smi, n_conditions, with_smiles, return_scores, return_separate)\n",
        "\n",
        "    def get_n_conditions(\n",
        "            self,\n",
        "            smi: str,\n",
        "            n_conditions: int = 10,\n",
        "            with_smiles=False,\n",
        "            return_scores=False,\n",
        "            return_separate=False,\n",
        "    ):\n",
        "        self.with_smiles = with_smiles\n",
        "\n",
        "        try:\n",
        "            pfp, rxnfp = self.smiles_to_fp(smi)\n",
        "            c1_input = []\n",
        "            r1_input = []\n",
        "            r2_input = []\n",
        "            s1_input = []\n",
        "            s2_input = []\n",
        "            inputs = [pfp, rxnfp, c1_input, r1_input, r2_input, s1_input, s2_input]\n",
        "\n",
        "            top_combos, top_combo_scores = self.predict_top_combos(\n",
        "                inputs=inputs, return_categories_only=return_separate\n",
        "            )\n",
        "\n",
        "            top_combo_scores = [float(score) for score in top_combo_scores]\n",
        "\n",
        "            top_combos, top_combo_scores = (\n",
        "                top_combos[:n_conditions],\n",
        "                top_combo_scores[:n_conditions],\n",
        "            )\n",
        "\n",
        "            if not return_separate:\n",
        "                top_combos = self.contexts_ehs_scores(top_combos[:n_conditions])\n",
        "\n",
        "            if return_scores:\n",
        "                return top_combos, top_combo_scores\n",
        "            else:\n",
        "                return top_combos\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Failed for reaction {smi} because {e}. Returning None.\")\n",
        "\n",
        "            return [[]]\n",
        "\n",
        "    def path_condition(self, n, path):\n",
        "        \"\"\"Recommends reaction conditions reaction path with multiple reactions.\n",
        "\n",
        "        Args:\n",
        "            n (int): Number of options to use at each step.\n",
        "            path (list): Reaction SMILES for each step.\n",
        "\n",
        "\n",
        "            Returns:\n",
        "                A list of reaction contexts with n options for each step.\n",
        "        \"\"\"\n",
        "        contexts = []\n",
        "\n",
        "        for rxn in path:\n",
        "            try:\n",
        "                pfp, rxnfp = self.smiles_to_fp(rxn)\n",
        "                c1_input = []\n",
        "                r1_input = []\n",
        "                r2_input = []\n",
        "                s1_input = []\n",
        "                s2_input = []\n",
        "                inputs = [pfp, rxnfp, c1_input, r1_input, r2_input, s1_input, s2_input]\n",
        "                top_combos = self.predict_top_combos(\n",
        "                    inputs=inputs,\n",
        "                    c1_rank_thres=1,\n",
        "                    s1_rank_thres=3,\n",
        "                    s2_rank_thres=1,\n",
        "                    r1_rank_thres=4,\n",
        "                    r2_rank_thres=1,\n",
        "                )\n",
        "                contexts.append(top_combos[:n])\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Failed for reaction {rxn} because {e}. Returning None.\")\n",
        "\n",
        "        return contexts\n",
        "\n",
        "    def predict_top_combos(\n",
        "            self,\n",
        "            inputs,\n",
        "            return_categories_only=False,\n",
        "            c1_rank_thres=2,\n",
        "            s1_rank_thres=3,\n",
        "            s2_rank_thres=1,\n",
        "            r1_rank_thres=3,\n",
        "            r2_rank_thres=1,\n",
        "    ):\n",
        "        \"\"\"Predicts top combos based on rank thresholds for individual elements.\n",
        "\n",
        "        Args:\n",
        "            inputs (list): Input values for model.\n",
        "            return_categories_only (bool, optional): Whether to only return the\n",
        "                categories. Used for testing. (default: {False})\n",
        "            c1_rank_thres (int, optional): Rank threshold for c1 (default: {2})\n",
        "            s1_rank_thres (int, optional): Rank threshold for s1 (default: {3})\n",
        "            s2_rank_thres (int, optional): Rank threshold for s2 (default: {1})\n",
        "            r1_rank_thres (int, optional): Rank threshold for r1 (default: {3})\n",
        "            r2_rank_thres (int, optional): Rank threshold for r2 (default: {1})\n",
        "\n",
        "        Returns:\n",
        "            list, list: Context combinations and overall scores from model\n",
        "        \"\"\"\n",
        "        # this function predicts the top combos based on rank thresholds for\n",
        "        # individual elements\n",
        "        context_combos = []\n",
        "        context_combo_scores = []\n",
        "        num_combos = c1_rank_thres * s1_rank_thres * s2_rank_thres * r1_rank_thres * r2_rank_thres\n",
        "        [\n",
        "            pfp,\n",
        "            rxnfp,\n",
        "            c1_input_user,\n",
        "            r1_input_user,\n",
        "            r2_input_user,\n",
        "            s1_input_user,\n",
        "            s2_input_user,\n",
        "        ] = inputs\n",
        "\n",
        "        fp_trans = self.fp_func([pfp, rxnfp])\n",
        "        if not c1_input_user:\n",
        "            c1_inputs = [fp_trans]\n",
        "            c1_pred = self.c1_func(c1_inputs).numpy()\n",
        "            c1_cdts = c1_pred[0].argsort()[-c1_rank_thres:][::-1]\n",
        "        else:\n",
        "            c1_cdts = np.nonzero(c1_input_user)[0]\n",
        "        # find the name of catalyst\n",
        "        for c1_cdt in c1_cdts:\n",
        "            c1_name = self.c1_dict[c1_cdt]\n",
        "            c1_input = np.zeros([1, self.c1_dim])\n",
        "            c1_input[0, c1_cdt] = 1\n",
        "            if not c1_input_user:\n",
        "                c1_sc = c1_pred[0][c1_cdt]\n",
        "            else:\n",
        "                c1_sc = 1\n",
        "            if not s1_input_user:\n",
        "                s1_inputs = [fp_trans, c1_input]\n",
        "                s1_pred = self.s1_func(s1_inputs).numpy()\n",
        "                s1_cdts = s1_pred[0].argsort()[-s1_rank_thres:][::-1]\n",
        "            else:\n",
        "                s1_cdts = np.nonzero(s1_input_user)[0]\n",
        "            for s1_cdt in s1_cdts:\n",
        "                s1_name = self.s1_dict[s1_cdt]\n",
        "                s1_input = np.zeros([1, self.s1_dim])\n",
        "                s1_input[0, s1_cdt] = 1\n",
        "                if not s1_input_user:\n",
        "                    s1_sc = s1_pred[0][s1_cdt]\n",
        "                else:\n",
        "                    s1_sc = 1\n",
        "                if not s2_input_user:\n",
        "                    s2_inputs = [fp_trans, c1_input, s1_input]\n",
        "                    s2_pred = self.s2_func(s2_inputs).numpy()\n",
        "                    s2_cdts = s2_pred[0].argsort()[-s2_rank_thres:][::-1]\n",
        "                else:\n",
        "                    s2_cdts = np.nonzero(s2_input_user)[0]\n",
        "                for s2_cdt in s2_cdts:\n",
        "                    s2_name = self.s2_dict[s2_cdt]\n",
        "                    s2_input = np.zeros([1, self.s2_dim])\n",
        "                    s2_input[0, s2_cdt] = 1\n",
        "                    if not s2_input_user:\n",
        "                        s2_sc = s2_pred[0][s2_cdt]\n",
        "                    else:\n",
        "                        s2_sc = 1\n",
        "                    if not r1_input_user:\n",
        "                        r1_inputs = [fp_trans, c1_input, s1_input, s2_input]\n",
        "                        r1_pred = self.r1_func(r1_inputs).numpy()\n",
        "                        r1_cdts = r1_pred[0].argsort()[-r1_rank_thres:][::-1]\n",
        "                    else:\n",
        "                        r1_cdts = np.nonzero(r1_input_user)[0]\n",
        "                    for r1_cdt in r1_cdts:\n",
        "                        r1_name = self.r1_dict[r1_cdt]\n",
        "                        r1_input = np.zeros([1, self.r1_dim])\n",
        "                        r1_input[0, r1_cdt] = 1\n",
        "                        if not r1_input_user:\n",
        "                            r1_sc = r1_pred[0][r1_cdt]\n",
        "                        else:\n",
        "                            r1_sc = 1\n",
        "                        if not r2_input_user:\n",
        "                            r2_inputs = [fp_trans, c1_input, s1_input, s2_input, r1_input]\n",
        "                            r2_pred = self.r2_func(r2_inputs).numpy()\n",
        "                            r2_cdts = r2_pred[0].argsort()[-r2_rank_thres:][::-1]\n",
        "                        else:\n",
        "                            r2_cdts = np.nonzero(r2_input_user)[0]\n",
        "                        for r2_cdt in r2_cdts:\n",
        "                            r2_name = self.r2_dict[r2_cdt]\n",
        "                            r2_input = np.zeros([1, self.r2_dim])\n",
        "                            r2_input[0, r2_cdt] = 1\n",
        "                            if not r2_input_user:\n",
        "                                r2_sc = r2_pred[0][r2_cdt]\n",
        "                            else:\n",
        "                                r2_sc = 1\n",
        "                            T_inputs = [fp_trans, c1_input, s1_input, s2_input, r1_input, r2_input]\n",
        "                            T_pred = self.T_func(T_inputs).numpy()\n",
        "                            # print(c1_name,s1_name,s2_name,r1_name,r2_name)\n",
        "                            cat_name = [c1_name]\n",
        "                            if r2_name == \"\":\n",
        "                                rgt_name = [r1_name]\n",
        "                            else:\n",
        "                                rgt_name = [r1_name, r2_name]\n",
        "                            if s2_name == \"\":\n",
        "                                slv_name = [s1_name]\n",
        "                            else:\n",
        "                                slv_name = [s1_name, s2_name]\n",
        "                            if self.with_smiles:\n",
        "                                rgt_name = [rgt for rgt in rgt_name if \"Reaxys\" not in rgt]\n",
        "                                slv_name = [slv for slv in slv_name if \"Reaxys\" not in slv]\n",
        "                                cat_name = [cat for cat in cat_name if \"Reaxys\" not in cat]\n",
        "                            # for testing purpose only, output order as training\n",
        "                            if return_categories_only:\n",
        "                                context_combos.append(\n",
        "                                    [\n",
        "                                        c1_name,\n",
        "                                        s1_name,\n",
        "                                        s2_name,\n",
        "                                        r1_name,\n",
        "                                        r2_name,\n",
        "                                        float(T_pred[0][0]),\n",
        "                                    ]\n",
        "                                )\n",
        "                            # else output format compatible with the overall framework\n",
        "                            else:\n",
        "                                context_combos.append(\n",
        "                                    [\n",
        "                                        float(T_pred[0][0]),\n",
        "                                        \".\".join(slv_name),\n",
        "                                        \".\".join(rgt_name),\n",
        "                                        \".\".join(cat_name),\n",
        "                                    ]\n",
        "                                )\n",
        "\n",
        "                            context_combo_scores.append(c1_sc * s1_sc * s2_sc * r1_sc * r2_sc)\n",
        "        context_ranks = list(num_combos + 1 - stats.rankdata(context_combo_scores))\n",
        "\n",
        "        context_combos = [context_combos[context_ranks.index(i + 1)] for i in range(num_combos)]\n",
        "        context_combo_scores = [\n",
        "            context_combo_scores[context_ranks.index(i + 1)] for i in range(num_combos)\n",
        "        ]\n",
        "\n",
        "        return context_combos, context_combo_scores\n",
        "\n",
        "    # def postprocess(self, context_combos):\n",
        "    #     \"\"\"Postprocess context combos by converting categories to names.\"\"\"\n",
        "    #     output = []\n",
        "    #     for c1_name, s1_name, s2_name, r1_name, r2_name, T_pred in context_combos:\n",
        "    #         cat_name = [c1_name]\n",
        "    #         if r2_name == \"\":\n",
        "    #             rgt_name = [r1_name]\n",
        "    #         else:\n",
        "    #             rgt_name = [r1_name, r2_name]\n",
        "    #         if s2_name == \"\":\n",
        "    #             slv_name = [s1_name]\n",
        "    #         else:\n",
        "    #             slv_name = [s1_name, s2_name]\n",
        "    #\n",
        "    #         if self.with_smiles:\n",
        "    #             rgt_name = [rgt for rgt in rgt_name if \"Reaxys\" not in rgt]\n",
        "    #             slv_name = [slv for slv in slv_name if \"Reaxys\" not in slv]\n",
        "    #             cat_name = [cat for cat in cat_name if \"Reaxys\" not in cat]\n",
        "    #\n",
        "    #         output.append(\n",
        "    #             [float(T_pred), \".\".join(slv_name), \".\".join(rgt_name), \".\".join(cat_name)]\n",
        "    #         )\n",
        "    #\n",
        "    #     return output\n",
        "\n",
        "    # Edited by Aaron Chen\n",
        "    def postprocess(self, context_combos):\n",
        "        \"\"\"Postprocess context combos by converting categories to names.\"\"\"\n",
        "        output = []\n",
        "        for c1_name, s1_name, s2_name, r1_name, r2_name, T_pred in context_combos:\n",
        "            cat_name = [c1_name]\n",
        "            if r2_name == \"\":\n",
        "                rgt_name = [r1_name]\n",
        "            else:\n",
        "                rgt_name = [r1_name, r2_name]\n",
        "            if s2_name == \"\":\n",
        "                slv_name = [s1_name]\n",
        "            else:\n",
        "                slv_name = [s1_name, s2_name]\n",
        "\n",
        "            if self.with_smiles:\n",
        "                rgt_name = [rgt for rgt in rgt_name if \"Reaxys\" not in rgt]\n",
        "                slv_name = [slv for slv in slv_name if \"Reaxys\" not in slv]\n",
        "                cat_name = [cat for cat in cat_name if \"Reaxys\" not in cat]\n",
        "\n",
        "            output.append(\n",
        "                [\n",
        "                    float(T_pred),\n",
        "                    \".\".join(slv_name),\n",
        "                    \".\".join(rgt_name),\n",
        "                    \".\".join(cat_name),\n",
        "                ]\n",
        "            )\n",
        "\n",
        "        return output\n",
        "\n",
        "    def load_ehs_dictionary(self, ehs_score_path):\n",
        "        \"\"\"Populates self.ehs_dict with mapping of solvent to EHS scores.\n",
        "\n",
        "        Assumes CSV input file does not have any entries that are not valid\n",
        "        ASKCOS solvents.\n",
        "\n",
        "        Unscored solvents receive a score of 7.\n",
        "        Otherwise, scores range 1 (best) to 6 (worst).\n",
        "\n",
        "        Args:\n",
        "            ehs_score_path (str): path to a csv file pairing valid ASKCOS solvents with an EHS score\n",
        "\n",
        "        Returns:\n",
        "            None\n",
        "        \"\"\"\n",
        "        self.ehs_dict = {}\n",
        "        with open(ehs_score_path, \"r\") as f:\n",
        "            for i, line in enumerate(f):\n",
        "                if i == 0:\n",
        "                    # Skip the first line (header)\n",
        "                    continue\n",
        "                a = line.strip().split(\",\")  # Remove whitespace and split by commas\n",
        "                key = a[2]\n",
        "                value = a[3]\n",
        "                if value.isdigit():\n",
        "                    value = int(value)\n",
        "                else:\n",
        "                    value = 7\n",
        "                self.ehs_dict[key] = value\n",
        "\n",
        "    def contexts_ehs_scores(self, top_combos):\n",
        "        \"\"\"Appends EHS score information to each context object in input list.\n",
        "\n",
        "        Adds a solvent EHS score and a boolean indicating whether the score is\n",
        "        the best out of all contexts in the input list.\n",
        "        \"\"\"\n",
        "        # Assign scores and get best score\n",
        "        best_score = self.combo_ehs_score(top_combos)\n",
        "        for item in top_combos:\n",
        "            item.append(item[-1] == best_score)\n",
        "        return top_combos\n",
        "\n",
        "    def combo_ehs_score(self, context_combos, best=True):\n",
        "        \"\"\"Determines EHS score information for each context in input list.\n",
        "\n",
        "        Modifies items in input list by appending EHS score.\n",
        "\n",
        "        Args:\n",
        "            context_combos (list): list of potential reaction conditions in the format returned by get.n.conditions\n",
        "            best (bool, optional): if True, returns best solvent score, otherwise returns average score (default: True)\n",
        "\n",
        "        Returns:\n",
        "            int if best=True, else float\n",
        "        \"\"\"\n",
        "        scores = []\n",
        "        for item in context_combos:\n",
        "            solvent = item[1]\n",
        "            if solvent in self.ehs_dict:\n",
        "                score = self.ehs_dict[solvent]\n",
        "            elif \".\" in solvent:  # solvent is actually multiple solvents\n",
        "                solvents = solvent.split(\".\")\n",
        "                sub_scores = []\n",
        "                for s in solvents:\n",
        "                    if s in self.ehs_dict:\n",
        "                        sub_scores.append(self.ehs_dict[s])\n",
        "                if sub_scores:\n",
        "                    score = sum(sub_scores) / len(sub_scores)\n",
        "                else:\n",
        "                    score = None\n",
        "            else:\n",
        "                score = None\n",
        "            item.append(score)\n",
        "            if score is not None:\n",
        "                scores.append(score)\n",
        "\n",
        "        if scores:\n",
        "            if best:\n",
        "                # Return best score\n",
        "                return min(scores)\n",
        "            else:\n",
        "                # Return average score\n",
        "                return sum(scores) / len(scores)\n",
        "        else:\n",
        "            return 8\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = NeuralNetContextRecommender().load()\n",
        "    print(\n",
        "        model.recommend(\n",
        "            \"CC1(C)OBOC1(C)C.Cc1ccc(Br)cc1>>Cc1cccc(B2OC(C)(C)C(C)(C)O2)c1\",\n",
        "            None,\n",
        "            10,\n",
        "            with_smiles=False,\n",
        "            return_scores=True,\n",
        "        )\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6DNPGp9nzRW",
        "outputId": "b185d8f3-28d6-427c-8fb9-70ff37de23a3"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([[102.30387115478516, 'C1COCCO1', 'CCN(CC)CC', \"Reaxys Name (1,1'-bis(diphenylphosphino)ferrocene)palladium(II) dichloride\", 5, False], [104.9278793334961, 'C1COCCO1', 'CCN(CC)CC', 'Cl[Pd](Cl)([P](c1ccccc1)(c1ccccc1)c1ccccc1)[P](c1ccccc1)(c1ccccc1)c1ccccc1', 5, False], [99.14100646972656, 'Cc1ccccc1', 'CCN(CC)CC', 'Cl[Pd](Cl)([P](c1ccccc1)(c1ccccc1)c1ccccc1)[P](c1ccccc1)(c1ccccc1)c1ccccc1', 3, True], [76.38555908203125, 'C1CCOC1', 'CCN(CC)CC', 'Cl[Pd](Cl)([P](c1ccccc1)(c1ccccc1)c1ccccc1)[P](c1ccccc1)(c1ccccc1)c1ccccc1', 4, False], [95.92562866210938, 'Cc1ccccc1', 'CCN(CC)CC', \"Reaxys Name (1,1'-bis(diphenylphosphino)ferrocene)palladium(II) dichloride\", 3, True], [75.68881225585938, 'C1CCOC1', 'CCN(CC)CC', \"Reaxys Name (1,1'-bis(diphenylphosphino)ferrocene)palladium(II) dichloride\", 4, False], [93.39191436767578, 'C1COCCO1', '', \"Reaxys Name (1,1'-bis(diphenylphosphino)ferrocene)palladium(II) dichloride\", 5, False], [97.87413024902344, 'C1COCCO1', 'CC(=O)[O-].[K+]', \"Reaxys Name (1,1'-bis(diphenylphosphino)ferrocene)palladium(II) dichloride\", 5, False], [95.84455108642578, 'C1COCCO1', '[MgH2]', 'Cl[Pd](Cl)([P](c1ccccc1)(c1ccccc1)c1ccccc1)[P](c1ccccc1)(c1ccccc1)c1ccccc1', 5, False], [67.86064910888672, 'C1CCOC1', '[MgH2]', 'Cl[Pd](Cl)([P](c1ccccc1)(c1ccccc1)c1ccccc1)[P](c1ccccc1)(c1ccccc1)c1ccccc1', 4, False]], [0.1975862979888916, 0.09385037422180176, 0.03205759450793266, 0.026748014613986015, 0.024693582206964493, 0.010140877217054367, 0.004813571460545063, 0.004163783509284258, 0.002136403461918235, 0.0018915414111688733])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0t47jOJ1n5P_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}